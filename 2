import numpy as np

class WarehouseRobot:
    def __init__(self):
        # 4x4 warehouse grid
        # 0 = empty, 1 = obstacle, 2 = item, 3 = goal
        self.grid = [
            [0, 2, 0, 3],
            [0, 1, 2, 0],
            [2, 0, 1, 0],
            [0, 0, 0, 2]
        ]
        
        self.rows = 4
        self.cols = 4
        self.rewards = {
            0: 0,    # empty space
            1: -2,   # obstacle penalty
            2: 2,    # item reward
            3: 5     # goal reward
        }
        
        # Define actions: up, down, left, right
        self.actions = ['U', 'D', 'L', 'R']
        self.action_effects = {
            'U': (-1, 0),
            'D': (1, 0),
            'L': (0, -1),
            'R': (0, 1)
        }
        
    def is_valid_position(self, row, col):
        """Check if position is inside warehouse"""
        return 0 <= row < self.rows and 0 <= col < self.cols
    
    def get_reward(self, row, col):
        """Get reward for being in a position"""
        cell_type = self.grid[row][col]
        return self.rewards[cell_type]
    
    def transition(self, state, action):
        """
        Move robot and return new state and reward
        state: (row, col) tuple
        action: 'U', 'D', 'L', 'R'
        """
        row, col = state
        
        if action not in self.action_effects:
            return state, 0  # Invalid action
        
        dr, dc = self.action_effects[action]
        new_row, new_col = row + dr, col + dc
        
        # Check if new position is valid
        if not self.is_valid_position(new_row, new_col):
            return state, 0  # Stay in place, no reward
        
        # Check if hitting obstacle
        if self.grid[new_row][new_col] == 1:
            return state, self.rewards[1]  # Hit obstacle, get penalty
        
        # Move to new position and get reward
        reward = self.get_reward(new_row, new_col)
        return (new_row, new_col), reward
    
    def print_grid_with_state(self, state=None):
        """Print warehouse grid with robot position"""
        print("\nWarehouse Layout:")
        print("  A B C D")
        
        for i in range(self.rows):
            print(f"{i+1} ", end="")
            for j in range(self.cols):
                if state and (i, j) == state:
                    print("ðŸ¤– ", end="")  # Robot
                elif self.grid[i][j] == 1:
                    print("â–ˆ ", end="")   # Obstacle
                elif self.grid[i][j] == 2:
                    print("ðŸ“¦ ", end="")  # Item
                elif self.grid[i][j] == 3:
                    print("ðŸŽ¯ ", end="")  # Goal
                else:
                    print(". ", end="")   # Empty
            print()
        
        print("\nLegend: ðŸ¤– = Robot, ðŸ“¦ = Item, ðŸŽ¯ = Goal, â–ˆ = Obstacle")

def policy_evaluation(robot, policy, gamma=0.9, iterations=100):
    """
    Evaluate a given policy using iterative policy evaluation
    
    robot: WarehouseRobot object
    policy: dictionary mapping states to actions
    gamma: discount factor (0.9 means future rewards are worth 90% of current)
    iterations: number of evaluation iterations
    """
    
    # Initialize value function for all states
    values = {}
    for i in range(robot.rows):
        for j in range(robot.cols):
            values[(i, j)] = 0
    
    print("Starting Policy Evaluation...")
    print(f"Discount factor Î³ = {gamma}")
    
    for iteration in range(iterations):
        new_values = values.copy()
        
        # Update value for each state
        for state in values:
            if robot.grid[state[0]][state[1]] in [3]:  # Terminal state (goal)
                continue
            
            # Get action from policy
            if state in policy:
                action = policy[state]
            else:
                # Default action if policy doesn't specify
                action = 'R' if state[1] < 3 else 'D'
            
            # Calculate expected value
            next_state, reward = robot.transition(state, action)
            new_value = reward + gamma * values[next_state]
            new_values[state] = new_value
        
        # Check for convergence
        max_change = max(abs(new_values[s] - values[s]) for s in values)
        values = new_values
        
        if max_change < 0.001:
            print(f"Converged after {iteration + 1} iterations")
            break
    
    return values

def main():
    # Create warehouse robot
    robot = WarehouseRobot()
    
    # Define a simple policy: always try to go right, then down
    policy = {}
    for i in range(robot.rows):
        for j in range(robot.cols):
            if j < 3:  # If not at right edge
                policy[(i, j)] = 'R'  # Go right
            else:
                policy[(i, j)] = 'D'  # Go down
    
    print("=== Warehouse Robot Policy Evaluation ===")
    print("Initial state: Robot at position A1 (0,0)")
    
    # Show warehouse
    robot.print_grid_with_state((0, 0))
    
    # Evaluate policy
    print("\n" + "="*50)
    print("Evaluating policy...")
    print("Policy: Always go right, if at right edge go down")
    print("="*50)
    
    values = policy_evaluation(robot, policy)
    
    # Display results
    print("\n" + "="*50)
    print("VALUE FUNCTION (Expected total reward from each state):")
    print("="*50)
    
    # Print value function in grid format
    print("\nValue Grid:")
    print("     A     B     C     D")
    print("  " + "-" * 25)
    
    for i in range(robot.rows):
        print(f"{i+1}| ", end="")
        for j in range(robot.cols):
            value = values[(i, j)]
            print(f"{value:5.2f} ", end="")
        print()
    
    print("\n" + "="*50)
    print("POLICY AT KEY LOCATIONS:")
    print("="*50)
    
    # Show policy at some key locations
    key_locations = [(0, 0), (0, 1), (1, 3), (3, 2)]
    for loc in key_locations:
        row, col = loc
        action = policy[loc]
        value = values[loc]
        cell_type = robot.grid[row][col]
        
        location_name = f"({row+1},{chr(65+col)})"
        cell_desc = {
            0: "Empty",
            1: "Obstacle",
            2: "Item",
            3: "Goal"
        }[cell_type]
        
        print(f"{location_name}: {cell_desc}")
        print(f"  Policy action: {action}")
        print(f"  Value: {value:.2f}")
        print()

if __name__ == "__main__":
    main()
